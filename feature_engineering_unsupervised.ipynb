{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sentiment Analysis\n",
    "Various popular lexicons are used for sentiment analysis, including the following.\n",
    "AFINN lexicon\n",
    "Bing Liuâ€™s lexicon\n",
    "MPQA subjectivity lexicon\n",
    "SentiWordNet\n",
    "VADER lexicon\n",
    "TextBlob lexicon\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Some Pre-Processing\n",
    "\n",
    "### Import necessary depencencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\rkaushik\\AppData\\Roaming\\nltk_data...",
      "\n",
      "[nltk_data]   Package wordnet is already up-to-date!",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import model_evaluation_utils as meu\n",
    "import gzip\n",
    "import json\n",
    "import multiprocessing\n",
    "import sqlite3\n",
    "from multiprocessing import Process\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "import pickle \n",
    "import math\n",
    "\n",
    "np.set_printoptions(precision=2, linewidth=80)\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "PROCESSED_FILENAME= './data/amazon_reviews_processed.pickle' \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load normalized data from disk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "f=open(PROCESSED_FILENAME, \"rb\")\n",
    "dataset = pickle.load(f)\n",
    "print('Total Rows on processed dataset: ' + str(len(dataset)))\n",
    "print('Sample of processed dataset. Notice the column named Clean_Review');\n",
    "dataset.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reviews = np.array(dataset['Clean_Review'])\n",
    "sentiments = np.array(dataset['sentiment'])\n",
    "\n",
    "# extract data for model evaluation\n",
    "train_reviews = reviews[:35000]\n",
    "train_sentiments = sentiments[:35000]\n",
    "\n",
    "test_reviews = reviews[35000:]\n",
    "test_sentiments = sentiments[35000:]\n",
    "sample_review_ids = [7626, 3533, 13010]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ============================================\n",
    "# Part A. Unsupervised (Lexicon) Sentiment Analysis\n",
    "# ============================================\n",
    "## 1.  Sentiment Analysis with AFINN\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "afn = Afinn(emoticons=True) \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict sentiment for sample reviews"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "REVIEW:",
      " ",
      "word fail whenever want describe feeling movie sequel flaw sure start subspecie not execute well enough special effect glorify movie herd movie mass consumer care quantity quality cheap fun depth crap like blade not even deserve capital letter underworlddracula 2000dracula 3000 good movie munch popcorn drink couple coke make subspecie superior effort anyone claim vampire fanatic hand obvious vampire romanian story set transylvania scene film location convince atmosphere not base action pack chase expensive orchestral music radu source atmosphere vampire look like behave add breathtakingly gloomy castle dark passageway situate romania include typical vampiric element movement shadow wall vampire take flight work art short like fascinated vampire feel appearance well setting sinister dark no good place look subspecie movie vampire journal brilliant spin former",
      "\n",
      "Actual Sentiment:",
      " ",
      "positive",
      "\n",
      "Predicted Sentiment polarity:",
      " ",
      "20.0",
      "\n",
      "------------------------------------------------------------",
      "\n",
      "REVIEW:",
      " ",
      "good family movie laugh wish not much school stuff like bully fill movie also seem little easy save piece land build mean flow easily make aware wildlife cute way introduce piece land fast runner little slow little hokey remind go back school oh dvd chock full goody not miss 7 10 movie 10 10 dvd extra well worth watch well worth time see",
      "\n",
      "Actual Sentiment:",
      " ",
      "positive",
      "\n",
      "Predicted Sentiment polarity:",
      " ",
      "12.0",
      "\n",
      "------------------------------------------------------------",
      "\n",
      "REVIEW:",
      " ",
      "opinion movie not good hardly find good thing say still would like explain conclude another bad movie decide watch costas mandylor star main reason watch till end like action movie understand movie build action rather story know not go detail come credibility story event even not explain scene lack sense reality look ridiculous beginning movie look quite promising tough good look specialist not tough smart funny partner must job turn bit different expect story take place cruise ship disaster happen ship turn leave alive struggle survive escape shark professional killer rise water furthermore movie quite violent main weapon beside disaster already take passenger gun successfully use many case personally miss good man man woman woman prefer fight family fun not think think movie shoot hurry without real vision try say make usual action movie trick bit something call love without real meaning result bad movie",
      "\n",
      "Actual Sentiment:",
      " ",
      "negative",
      "\n",
      "Predicted Sentiment polarity:",
      " ",
      "2.0",
      "\n",
      "------------------------------------------------------------",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
    "    print('REVIEW:', review)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    print('Predicted Sentiment polarity:', afn.score(review))\n",
    "    print('-'*60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict sentiment for test dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "sentiment_polarity = [afn.score(review) for review in test_reviews]\n",
    "predicted_sentiments = [1 if score >= 1.0 else 0 for score in sentiment_polarity]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate model performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model Performance metrics:",
      "\n",
      "------------------------------",
      "\n",
      "Accuracy:",
      " ",
      "0.7054",
      "\n",
      "Precision:",
      " ",
      "0.7212",
      "\n",
      "Recall:",
      " ",
      "0.7054",
      "\n",
      "F1 Score:",
      " ",
      "0.6993",
      "\n",
      "\nModel Classification report:",
      "\n",
      "------------------------------",
      "\n",
      "              precision    recall  f1-score   support\n\n    positive       0.66      0.84      0.74      7587\n    negative       0.78      0.56      0.65      7413\n\n    accuracy                           0.71     15000\n   macro avg       0.72      0.70      0.70     15000\nweighted avg       0.72      0.71      0.70     15000\n",
      "\n",
      "\nPrediction Confusion Matrix:",
      "\n",
      "------------------------------",
      "\n",
      "                 Predicted:         \n                   positive negative\nActual: positive       6405     1182\n        negative       3237     4176",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\rkaushik\\PycharmProjects\\ML1010_InClass\\Day1\\3_sentiment\\model_evaluation_utils.py:60: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n  labels=level_labels),\n",
      "C:\\Users\\rkaushik\\PycharmProjects\\ML1010_InClass\\Day1\\3_sentiment\\model_evaluation_utils.py:62: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n  labels=level_labels))\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predicted_sentiments, \n",
    "                                  classes=[1, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Sentiment Analysis with SentiWordNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n[nltk_data]     C:\\Users\\rkaushik\\AppData\\Roaming\\nltk_data...",
      "\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Positive Polarity Score:",
      " ",
      "0.875",
      "\n",
      "Negative Polarity Score:",
      " ",
      "0.125",
      "\n",
      "Objective Score:",
      " ",
      "0.0",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "nltk.download('sentiwordnet')\n",
    "\n",
    "awesome = list(swn.senti_synsets('awesome', 'a'))[0]\n",
    "print('Positive Polarity Score:', awesome.pos_score())\n",
    "print('Negative Polarity Score:', awesome.neg_score())\n",
    "print('Objective Score:', awesome.obj_score())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build model\n",
    "For each word in  the review, add up the sentiment score of words that are NN, VB, JJ, RB if it's in the lexicon dictionary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def analyze_sentiment_sentiwordnet_lexicon(review,\n",
    "                                           verbose=False):\n",
    "\n",
    "    # tokenize and POS tag text tokens\n",
    "    tagged_text = [(token.text, token.tag_) for token in utils.nlp(review)]\n",
    "    pos_score = neg_score = token_count = obj_score = 0\n",
    "    # get wordnet synsets based on POS tags\n",
    "    # get sentiment scores if synsets are found\n",
    "    for word, tag in tagged_text:\n",
    "        ss_set = None\n",
    "        if 'NN' in tag and list(swn.senti_synsets(word, 'n')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'n'))[0]\n",
    "        elif 'VB' in tag and list(swn.senti_synsets(word, 'v')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'v'))[0]\n",
    "        elif 'JJ' in tag and list(swn.senti_synsets(word, 'a')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'a'))[0]\n",
    "        elif 'RB' in tag and list(swn.senti_synsets(word, 'r')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'r'))[0]\n",
    "        # if senti-synset is found        \n",
    "        if ss_set:\n",
    "            # add scores for all found synsets\n",
    "            pos_score += ss_set.pos_score()\n",
    "            neg_score += ss_set.neg_score()\n",
    "            obj_score += ss_set.obj_score()\n",
    "            token_count += 1\n",
    "    \n",
    "    # aggregate final scores\n",
    "    final_score = pos_score - neg_score\n",
    "    norm_final_score = round(float(final_score) / token_count, 2)\n",
    "    final_sentiment = 0 if norm_final_score >= 0 else 0\n",
    "    if verbose:\n",
    "        norm_obj_score = round(float(obj_score) / token_count, 2)\n",
    "        norm_pos_score = round(float(pos_score) / token_count, 2)\n",
    "        norm_neg_score = round(float(neg_score) / token_count, 2)\n",
    "        # to display results in a nice table\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, norm_obj_score, norm_pos_score, \n",
    "                                         norm_neg_score, norm_final_score]],\n",
    "                                       columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                             ['Predicted Sentiment', 'Objectivity',\n",
    "                                                              1, 0, 'Overall']], \n",
    "                                                             labels=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
    "        print(sentiment_frame)\n",
    "        \n",
    "    return final_sentiment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict sentiment for sample reviews"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "REVIEW:",
      " ",
      "word fail whenever want describe feeling movie sequel flaw sure start subspecie not execute well enough special effect glorify movie herd movie mass consumer care quantity quality cheap fun depth crap like blade not even deserve capital letter underworlddracula 2000dracula 3000 good movie munch popcorn drink couple coke make subspecie superior effort anyone claim vampire fanatic hand obvious vampire romanian story set transylvania scene film location convince atmosphere not base action pack chase expensive orchestral music radu source atmosphere vampire look like behave add breathtakingly gloomy castle dark passageway situate romania include typical vampiric element movement shadow wall vampire take flight work art short like fascinated vampire feel appearance well setting sinister dark no good place look subspecie movie vampire journal brilliant spin former",
      "\n",
      "Actual Sentiment:",
      " ",
      "positive",
      "\n",
      "     SENTIMENT STATS:                                      \n  Predicted Sentiment Objectivity Positive Negative Overall\n0            positive        0.85     0.08     0.07    0.01",
      "\n",
      "------------------------------------------------------------",
      "\n",
      "REVIEW:",
      " ",
      "good family movie laugh wish not much school stuff like bully fill movie also seem little easy save piece land build mean flow easily make aware wildlife cute way introduce piece land fast runner little slow little hokey remind go back school oh dvd chock full goody not miss 7 10 movie 10 10 dvd extra well worth watch well worth time see",
      "\n",
      "Actual Sentiment:",
      " ",
      "positive",
      "\n",
      "     SENTIMENT STATS:                                      \n  Predicted Sentiment Objectivity Positive Negative Overall\n0            positive        0.84     0.09     0.06    0.03",
      "\n",
      "------------------------------------------------------------",
      "\n",
      "REVIEW:",
      " ",
      "opinion movie not good hardly find good thing say still would like explain conclude another bad movie decide watch costas mandylor star main reason watch till end like action movie understand movie build action rather story know not go detail come credibility story event even not explain scene lack sense reality look ridiculous beginning movie look quite promising tough good look specialist not tough smart funny partner must job turn bit different expect story take place cruise ship disaster happen ship turn leave alive struggle survive escape shark professional killer rise water furthermore movie quite violent main weapon beside disaster already take passenger gun successfully use many case personally miss good man man woman woman prefer fight family fun not think think movie shoot hurry without real vision try say make usual action movie trick bit something call love without real meaning result bad movie",
      "\n",
      "Actual Sentiment:",
      " ",
      "negative",
      "\n",
      "     SENTIMENT STATS:                                      \n  Predicted Sentiment Objectivity Positive Negative Overall\n0            positive        0.82     0.09     0.09     0.0",
      "\n",
      "------------------------------------------------------------",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
    "    print('REVIEW:', review)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    pred = analyze_sentiment_sentiwordnet_lexicon(review, verbose=True)    \n",
    "    print('-'*60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict sentiment for test dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "predicted_sentiments = [analyze_sentiment_sentiwordnet_lexicon(review, verbose=False) for review in test_reviews]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate model performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model Performance metrics:",
      "\n",
      "------------------------------",
      "\n",
      "Accuracy:",
      " ",
      "0.6776",
      "\n",
      "Precision:",
      " ",
      "0.6804",
      "\n",
      "Recall:",
      " ",
      "0.6776",
      "\n",
      "F1 Score:",
      " ",
      "0.6758",
      "\n",
      "\nModel Classification report:",
      "\n",
      "------------------------------",
      "\n",
      "              precision    recall  f1-score   support\n\n    positive       0.66      0.75      0.70      7587\n    negative       0.70      0.61      0.65      7413\n\n    accuracy                           0.68     15000\n   macro avg       0.68      0.68      0.68     15000\nweighted avg       0.68      0.68      0.68     15000\n",
      "\n",
      "\nPrediction Confusion Matrix:",
      "\n",
      "------------------------------",
      "\n",
      "                 Predicted:         \n                   positive negative\nActual: positive       5679     1908\n        negative       2928     4485",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predicted_sentiments, \n",
    "                                  classes=[1, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Sentiment Analysis with VADER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     C:\\Users\\rkaushik\\AppData\\Roaming\\nltk_data...",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 21
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.downloader.download('vader_lexicon')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def analyze_sentiment_vader_lexicon(review, \n",
    "                                    threshold=0.1,\n",
    "                                    verbose=False):\n",
    "    # pre-process text\n",
    "    review = tn.strip_html_tags(review)\n",
    "    review = tn.remove_accented_chars(review)\n",
    "    review = tn.expand_contractions(review)\n",
    "    \n",
    "    # analyze the sentiment for review\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    # get aggregate scores and final sentiment\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 1 if agg_score >= threshold\\\n",
    "                                   else 0\n",
    "    if verbose:\n",
    "        # display detailed sentiment statistics\n",
    "        positive = str(round(scores['pos'], 2)*100)+'%'\n",
    "        final = round(agg_score, 2)\n",
    "        negative = str(round(scores['neg'], 2)*100)+'%'\n",
    "        neutral = str(round(scores['neu'], 2)*100)+'%'\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, final, positive,\n",
    "                                        negative, neutral]],\n",
    "                                        columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                                      ['Predicted Sentiment', 'Polarity Score',\n",
    "                                                                       1, 0, 'Neutral']], \n",
    "                                                              labels=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
    "        print(sentiment_frame)\n",
    "    \n",
    "    return final_sentiment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict sentiment for sample reviews"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "REVIEW:",
      " ",
      "word fail whenever want describe feeling movie sequel flaw sure start subspecie not execute well enough special effect glorify movie herd movie mass consumer care quantity quality cheap fun depth crap like blade not even deserve capital letter underworlddracula 2000dracula 3000 good movie munch popcorn drink couple coke make subspecie superior effort anyone claim vampire fanatic hand obvious vampire romanian story set transylvania scene film location convince atmosphere not base action pack chase expensive orchestral music radu source atmosphere vampire look like behave add breathtakingly gloomy castle dark passageway situate romania include typical vampiric element movement shadow wall vampire take flight work art short like fascinated vampire feel appearance well setting sinister dark no good place look subspecie movie vampire journal brilliant spin former",
      "\n",
      "Actual Sentiment:",
      " ",
      "positive",
      "\n",
      "     SENTIMENT STATS:                                                     \n  Predicted Sentiment Polarity Score             Positive Negative Neutral\n0            positive           0.98  28.000000000000004%    11.0%   61.0%",
      "\n",
      "------------------------------------------------------------",
      "\n",
      "REVIEW:",
      " ",
      "good family movie laugh wish not much school stuff like bully fill movie also seem little easy save piece land build mean flow easily make aware wildlife cute way introduce piece land fast runner little slow little hokey remind go back school oh dvd chock full goody not miss 7 10 movie 10 10 dvd extra well worth watch well worth time see",
      "\n",
      "Actual Sentiment:",
      " ",
      "positive",
      "\n",
      "     SENTIMENT STATS:                                                     \n  Predicted Sentiment Polarity Score Positive Negative             Neutral\n0            positive           0.97    39.0%     4.0%  57.99999999999999%",
      "\n",
      "------------------------------------------------------------",
      "\n",
      "REVIEW:",
      " ",
      "opinion movie not good hardly find good thing say still would like explain conclude another bad movie decide watch costas mandylor star main reason watch till end like action movie understand movie build action rather story know not go detail come credibility story event even not explain scene lack sense reality look ridiculous beginning movie look quite promising tough good look specialist not tough smart funny partner must job turn bit different expect story take place cruise ship disaster happen ship turn leave alive struggle survive escape shark professional killer rise water furthermore movie quite violent main weapon beside disaster already take passenger gun successfully use many case personally miss good man man woman woman prefer fight family fun not think think movie shoot hurry without real vision try say make usual action movie trick bit something call love without real meaning result bad movie",
      "\n",
      "Actual Sentiment:",
      " ",
      "negative",
      "\n",
      "     SENTIMENT STATS:                                                     \n  Predicted Sentiment Polarity Score Positive Negative             Neutral\n0            negative          -0.98    12.0%    31.0%  56.00000000000001%",
      "\n",
      "------------------------------------------------------------",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
    "    print('REVIEW:', review)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    pred = analyze_sentiment_vader_lexicon(review, threshold=0.4, verbose=True)    \n",
    "    print('-'*60)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predict sentiment for test dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "predicted_sentiments = [analyze_sentiment_vader_lexicon(review, threshold=0.4, verbose=False) for review in test_reviews]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate model performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model Performance metrics:",
      "\n",
      "------------------------------",
      "\n",
      "Accuracy:",
      " ",
      "0.6964",
      "\n",
      "Precision:",
      " ",
      "0.704",
      "\n",
      "Recall:",
      " ",
      "0.6964",
      "\n",
      "F1 Score:",
      " ",
      "0.6929",
      "\n",
      "\nModel Classification report:",
      "\n",
      "------------------------------",
      "\n",
      "              precision    recall  f1-score   support\n\n    positive       0.67      0.80      0.73      7587\n    negative       0.74      0.59      0.66      7413\n\n    accuracy                           0.70     15000\n   macro avg       0.70      0.70      0.69     15000\nweighted avg       0.70      0.70      0.69     15000\n",
      "\n",
      "\nPrediction Confusion Matrix:",
      "\n",
      "------------------------------",
      "\n",
      "                 Predicted:         \n                   positive negative\nActual: positive       6066     1521\n        negative       3033     4380",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predicted_sentiments, \n",
    "                                  classes=[1, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}