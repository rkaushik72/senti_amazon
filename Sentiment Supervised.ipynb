{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import necessary depencencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dropout, Activation, Dense\n",
    "from keras.models import Sequential\n",
    "import model_evaluation_utils as meu\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, SpatialDropout1D\n",
    "from keras.layers import LSTM\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2, linewidth=80)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load normalized data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train and test datasets\n",
    "train_reviews = utils.readFromDisk('train_reviews')\n",
    "train_sentiments = utils.readFromDisk('train_sentiments')\n",
    "test_reviews = utils.readFromDisk('test_reviews')\n",
    "test_sentiments = utils.readFromDisk('test_sentiments')\n",
    "tokenized_train = utils.readFromDisk('tokenized_train')\n",
    "tokenized_test = utils.readFromDisk('tokenized_test')\n",
    "train_sentiments_encoded = utils.readFromDisk('train_sentiments_encoded')\n",
    "test_sentiments_encoded = utils.readFromDisk('test_sentiments_encoded')\n",
    "\n",
    "#glove features\n",
    "# feature engineering with GloVe model\n",
    "train_glove_features = utils.readFromDisk('train_glove_features')\n",
    "test_glove_features = utils.readFromDisk('test_glove_features')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Traditional Supervised Machine Learning Models\n",
    "## Model Training, Prediction and Performance Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', max_iter=500, C=1)\n",
    "svm = SGDClassifier(loss='hinge', max_iter=500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "lr_predictions = meu.train_predict_model(classifier=lr, \n",
    "                                             train_features=train_glove_features, train_labels=train_sentiments,\n",
    "                                             test_features=test_glove_features, test_labels=test_sentiments)\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_predictions,\n",
    "                                      classes=[1,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svm_predictions = meu.train_predict_model(classifier=svm, \n",
    "                                             train_features=train_glove_features, train_labels=train_sentiments,\n",
    "                                             test_features=test_glove_features, test_labels=test_sentiments)\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=svm_predictions,\n",
    "                                      classes=[1,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Newer Supervised Deep Learning Models\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling with deep neural networks "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building Deep neural network architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def construct_deepnn_architecture(num_input_features):\n",
    "    dnn_model = Sequential()\n",
    "    dnn_model.add(Dense(512, activation='relu', input_shape=(num_input_features,)))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    dnn_model.add(Dense(512, activation='relu'))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    dnn_model.add(Dense(512, activation='relu'))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    dnn_model.add(Dense(2))\n",
    "    dnn_model.add(Activation('softmax'))\n",
    "\n",
    "    dnn_model.compile(loss='categorical_crossentropy', optimizer='adam',                 \n",
    "                      metrics=['accuracy'])\n",
    "    return dnn_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Training, Prediction and Performance Evaluation\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "glove_dnn = construct_deepnn_architecture(num_input_features=300)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "glove_dnn.fit(train_glove_features, train_sentiments_encoded, epochs=5, batch_size=batch_size, \n",
    "              shuffle=True, validation_split=0.1, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "le = utils.readFromDisk('label_encoder')\n",
    "y_pred = glove_dnn.predict_classes(test_glove_features)\n",
    "dnn_predictions = le.inverse_transform(y_pred) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=dnn_predictions, \n",
    "                                      classes=[1,0])  \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# XGBoost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgc = xgb.XGBClassifier(n_estimators=500, max_depth=5, base_score=0.5,objective='binary:logistic', random_state=42)\n",
    "xgc.fit(train_glove_features, train_sentiments)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgc_predictions = xgc.predict(test_reviews)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=xgc_predictions, \n",
    "                                      classes=[1,0])  \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Vocabulary Mapping (word to index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# build word to index vocabulary\n",
    "token_counter = Counter([token for review in tokenized_train for token in review])\n",
    "vocab_map = {item[0]: index+1 for index, item in enumerate(dict(token_counter).items())}\n",
    "max_index = np.max(list(vocab_map.values()))\n",
    "vocab_map['PAD_INDEX'] = 0\n",
    "vocab_map['NOT_FOUND_INDEX'] = max_index+1\n",
    "vocab_size = len(vocab_map)\n",
    "# view vocabulary size and part of the vocabulary map\n",
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Sample slice of vocabulary map:', dict(list(vocab_map.items())[10:20]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Encode and Pad datasets & Encode prediction class labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get max length of train corpus and initialize label encoder\n",
    "max_len = np.max([len(review) for review in tokenized_train])\n",
    "\n",
    "## Train reviews data corpus\n",
    "# Convert tokenized text reviews to numeric vectors\n",
    "train_X = [[vocab_map[token] for token in tokenized_review] for tokenized_review in tokenized_train]\n",
    "train_X = sequence.pad_sequences(train_X, maxlen=max_len) # pad \n",
    "\n",
    "## Test reviews data corpus\n",
    "# Convert tokenized text reviews to numeric vectors\n",
    "test_X = [[vocab_map[token] if vocab_map.get(token) else vocab_map['NOT_FOUND_INDEX'] \n",
    "           for token in tokenized_review] \n",
    "              for tokenized_review in tokenized_test]\n",
    "test_X = sequence.pad_sequences(test_X, maxlen=max_len)\n",
    "\n",
    "# view vector shapes\n",
    "print('Max length of train review vectors:', max_len)\n",
    "print('Train review vectors shape:', train_X.shape, ' Test review vectors shape:', test_X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build the LSTM Model Architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 128 # dimension for dense embeddings for each token\n",
    "LSTM_DIM = 64 # total LSTM units\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=max_len))\n",
    "lstm.add(SpatialDropout1D(0.2))\n",
    "lstm.add(LSTM(LSTM_DIM, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm.add(Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "lstm.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(lstm.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize model architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(lstm, show_shapes=True, show_layer_names=False, \n",
    "                 rankdir='LR').create(prog='dot', format='svg'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "lstm.fit(train_X, train_sentiments_encoded, epochs=5, batch_size=batch_size, \n",
    "          shuffle=True, validation_split=0.1, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict and Evaluate Model Performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lstm_pred_test = lstm.predict_classes(test_X)\n",
    "lstm_predictions = le.inverse_transform(lstm_pred_test.flatten())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lstm_predictions, \n",
    "                                      classes=[1,0])  \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ROC curves"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(0).clf()\n",
    "\n",
    "color = ['blue', 'orange', 'red', 'green', 'coral',\n",
    "             'grey', 'indigo', 'gold', 'lime', 'olive',\n",
    "             'pink', 'navy', 'magenta', 'yellow', 'tomato',\n",
    "             'turquoise', 'yellowgreen', 'maroon', 'lightblue']\n",
    "mlr=[]\n",
    "msvm=[]\n",
    "mdnn=[]\n",
    "mxgc=[]\n",
    "mlstm=[]\n",
    "\n",
    "def metricsAndROC(pred,metricsArray,rocTitle,colorIndex):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_sentiments, pred)\n",
    "    auc = metrics.roc_auc_score(test_sentiments, pred)\n",
    "    metricsArray.append(metrics.f1_score(test_sentiments, pred))\n",
    "    metricsArray.append(metrics.precision_score(test_sentiments, pred))\n",
    "    metricsArray.append(metrics.accuracy_score(test_sentiments, pred))\n",
    "    metricsArray.append(metrics.recall_score(test_sentiments, pred))\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr,color=color[colorIndex], label=rocTitle.format(auc))\n",
    "\n",
    "\n",
    "\n",
    "metricsAndROC(lr_predictions,mlr,'LR',0)\n",
    "metricsAndROC(svm_predictions,msvm,'SVM',0)\n",
    "metricsAndROC(xgc_predictions,mxgc,'XGBoost',0)\n",
    "metricsAndROC(lstm_predictions,lstm,'LSTM',0)\n",
    "\n",
    "\n",
    "\n",
    "#show the roc curve now\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "# show the legend\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_groups = 4\n",
    "index = np.arange(n_groups)\n",
    "bar_width = .1\n",
    "\n",
    "plt.bar(index,mlr, bar_width, color=color[0], label='BOW')\n",
    "\n",
    "'''\n",
    "z=index + bar_width\n",
    "plt.bar(z, mngram, bar_width, color=color[1],label='NGRAM')\n",
    "\n",
    "\n",
    "\n",
    "z=z+ bar_width\n",
    "plt.bar(z, mtfidf, bar_width, color=color[2], label='TFIDF')\n",
    "\n",
    "z=z+ bar_width\n",
    "plt.bar(z,mw2v , bar_width, color=color[3], label='W2V')\n",
    "\n",
    "z=z+ bar_width\n",
    "plt.bar(z,mglove , bar_width,color=color[4], label='Glove')\n",
    "\n",
    "z=z+ bar_width\n",
    "plt.bar(z,mft , bar_width, color=color[5], label='FastText')\n",
    "'''\n",
    "\n",
    "#ax.set_xlabel('Metric')\n",
    "#ax.set_ylabel('Value')\n",
    "#ax.set_title('Comparison of Feature Engineering Models on Amazon Reviews')\n",
    "#ax.set_xticks(index + bar_width / 2)\n",
    "pltLabels=['F1','PRECISION','ACCURACY','RECALL']\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Model Metrics', fontweight='bold')\n",
    "plt.xticks([r + bar_width for r in range(n_groups)], pltLabels)\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend(frameon=False,ncol=3, loc='lower left')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}